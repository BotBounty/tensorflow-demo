{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Training data size:  55000\n",
      "Testing data size:  10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python import learn\n",
    "from sklearn import metrics\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def transform(Y):\n",
    "    y = []\n",
    "    for label in Y:\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == 1:\n",
    "                y.append(i)\n",
    "                break\n",
    "    return y\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "print \"Training data size: \", mnist.train.num_examples\n",
    "print \"Testing data size: \", mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用skflow实现LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 1.47398\n",
      "Step #199, avg. train loss: 0.89326\n",
      "Step #299, avg. train loss: 0.72736\n",
      "Step #399, avg. train loss: 0.64083\n",
      "Step #499, avg. train loss: 0.58898\n",
      "Step #600, epoch #1, avg. train loss: 0.55098\n",
      "Step #700, epoch #1, avg. train loss: 0.52310\n",
      "Step #800, epoch #1, avg. train loss: 0.51131\n",
      "Step #900, epoch #1, avg. train loss: 0.48827\n",
      "Step #1000, epoch #1, avg. train loss: 0.49028\n",
      "Step #1100, epoch #2, avg. train loss: 0.46843\n",
      "Step #1200, epoch #2, avg. train loss: 0.46281\n",
      "Step #1300, epoch #2, avg. train loss: 0.45451\n",
      "Step #1400, epoch #2, avg. train loss: 0.43103\n",
      "Step #1500, epoch #2, avg. train loss: 0.42987\n",
      "Step #1600, epoch #2, avg. train loss: 0.41931\n",
      "Step #1700, epoch #3, avg. train loss: 0.42471\n",
      "Step #1800, epoch #3, avg. train loss: 0.41586\n",
      "Step #1900, epoch #3, avg. train loss: 0.40235\n",
      "Step #2000, epoch #3, avg. train loss: 0.40717\n",
      "Step #2100, epoch #3, avg. train loss: 0.40040\n",
      "Step #2200, epoch #4, avg. train loss: 0.40519\n",
      "Step #2300, epoch #4, avg. train loss: 0.39310\n",
      "Step #2400, epoch #4, avg. train loss: 0.37741\n",
      "Step #2500, epoch #4, avg. train loss: 0.39962\n",
      "Step #2600, epoch #4, avg. train loss: 0.39373\n",
      "Step #2700, epoch #4, avg. train loss: 0.37917\n",
      "Step #2800, epoch #5, avg. train loss: 0.38485\n",
      "Step #2900, epoch #5, avg. train loss: 0.38364\n",
      "Step #3000, epoch #5, avg. train loss: 0.37839\n",
      "Step #3100, epoch #5, avg. train loss: 0.37918\n",
      "Step #3200, epoch #5, avg. train loss: 0.36544\n",
      "Step #3300, epoch #6, avg. train loss: 0.36478\n",
      "Step #3400, epoch #6, avg. train loss: 0.38137\n",
      "Step #3500, epoch #6, avg. train loss: 0.36716\n",
      "Step #3600, epoch #6, avg. train loss: 0.36150\n",
      "Step #3700, epoch #6, avg. train loss: 0.35597\n",
      "Step #3800, epoch #6, avg. train loss: 0.36512\n",
      "Step #3900, epoch #7, avg. train loss: 0.36146\n",
      "Step #4000, epoch #7, avg. train loss: 0.34870\n",
      "Step #4100, epoch #7, avg. train loss: 0.35626\n",
      "Step #4200, epoch #7, avg. train loss: 0.35665\n",
      "Step #4300, epoch #7, avg. train loss: 0.35570\n",
      "Step #4400, epoch #8, avg. train loss: 0.35766\n",
      "Step #4500, epoch #8, avg. train loss: 0.35865\n",
      "Step #4600, epoch #8, avg. train loss: 0.34527\n",
      "Step #4700, epoch #8, avg. train loss: 0.35578\n",
      "Step #4800, epoch #8, avg. train loss: 0.35639\n",
      "Step #4900, epoch #8, avg. train loss: 0.34804\n",
      "Step #5000, epoch #9, avg. train loss: 0.33372\n",
      "Test accuracy: 0.912100\n"
     ]
    }
   ],
   "source": [
    "classifier = learn.TensorFlowLinearClassifier(n_classes=10, batch_size=100, steps=5000, learning_rate=0.01)\n",
    "classifier.fit(mnist.train.images, transform(mnist.train.labels))\n",
    "score = metrics.accuracy_score(transform(mnist.test.labels), classifier.predict(mnist.test.images))\n",
    "print('Test accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用skflow实现DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.70828\n",
      "Step #199, avg. train loss: 0.36776\n",
      "Step #299, avg. train loss: 0.28714\n",
      "Step #399, avg. train loss: 0.24735\n",
      "Step #499, avg. train loss: 0.22045\n",
      "Step #599, avg. train loss: 0.20342\n",
      "Step #699, avg. train loss: 0.17905\n",
      "Step #799, avg. train loss: 0.17126\n",
      "Step #899, avg. train loss: 0.16221\n",
      "Step #999, avg. train loss: 0.16507\n",
      "Step #1099, avg. train loss: 0.13358\n",
      "Step #1199, avg. train loss: 0.12631\n",
      "Step #1299, avg. train loss: 0.12040\n",
      "Step #1399, avg. train loss: 0.10987\n",
      "Step #1499, avg. train loss: 0.13684\n",
      "Step #1599, avg. train loss: 0.11119\n",
      "Step #1699, avg. train loss: 0.12187\n",
      "Step #1800, epoch #1, avg. train loss: 0.09357\n",
      "Step #1900, epoch #1, avg. train loss: 0.07177\n",
      "Step #2000, epoch #1, avg. train loss: 0.08368\n",
      "Step #2100, epoch #1, avg. train loss: 0.08970\n",
      "Step #2200, epoch #1, avg. train loss: 0.09113\n",
      "Step #2300, epoch #1, avg. train loss: 0.07333\n",
      "Step #2400, epoch #1, avg. train loss: 0.07422\n",
      "Step #2500, epoch #1, avg. train loss: 0.09545\n",
      "Step #2600, epoch #1, avg. train loss: 0.08472\n",
      "Step #2700, epoch #1, avg. train loss: 0.07335\n",
      "Step #2800, epoch #1, avg. train loss: 0.08330\n",
      "Step #2900, epoch #1, avg. train loss: 0.07833\n",
      "Step #3000, epoch #1, avg. train loss: 0.08652\n",
      "Step #3100, epoch #1, avg. train loss: 0.08431\n",
      "Step #3200, epoch #1, avg. train loss: 0.08106\n",
      "Step #3300, epoch #1, avg. train loss: 0.09003\n",
      "Step #3400, epoch #1, avg. train loss: 0.08157\n",
      "Step #3500, epoch #2, avg. train loss: 0.06060\n",
      "Step #3600, epoch #2, avg. train loss: 0.05268\n",
      "Step #3700, epoch #2, avg. train loss: 0.05388\n",
      "Step #3800, epoch #2, avg. train loss: 0.05032\n",
      "Step #3900, epoch #2, avg. train loss: 0.05514\n",
      "Step #4000, epoch #2, avg. train loss: 0.05016\n",
      "Step #4100, epoch #2, avg. train loss: 0.05515\n",
      "Step #4200, epoch #2, avg. train loss: 0.05752\n",
      "Step #4300, epoch #2, avg. train loss: 0.04259\n",
      "Step #4400, epoch #2, avg. train loss: 0.04752\n",
      "Step #4500, epoch #2, avg. train loss: 0.05512\n",
      "Step #4600, epoch #2, avg. train loss: 0.05996\n",
      "Step #4700, epoch #2, avg. train loss: 0.04183\n",
      "Step #4800, epoch #2, avg. train loss: 0.04750\n",
      "Step #4900, epoch #2, avg. train loss: 0.05605\n",
      "Step #5000, epoch #2, avg. train loss: 0.05638\n",
      "Test accuracy: 0.977100\n"
     ]
    }
   ],
   "source": [
    "# Single hidden layer with 10000 nodes.\n",
    "classifier = learn.TensorFlowDNNClassifier(hidden_units=[1000], n_classes=10, steps=5000)\n",
    "classifier.fit(mnist.train.images, transform(mnist.train.labels))\n",
    "score = metrics.accuracy_score(transform(mnist.test.labels), classifier.predict(mnist.test.images))\n",
    "print('Test accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.80489\n",
      "Step #199, avg. train loss: 0.41654\n",
      "Step #299, avg. train loss: 0.33345\n",
      "Step #399, avg. train loss: 0.29082\n",
      "Step #499, avg. train loss: 0.25656\n",
      "Step #599, avg. train loss: 0.24756\n",
      "Step #699, avg. train loss: 0.21432\n",
      "Step #799, avg. train loss: 0.21516\n",
      "Step #899, avg. train loss: 0.19492\n",
      "Step #999, avg. train loss: 0.19506\n",
      "Step #1099, avg. train loss: 0.16465\n",
      "Step #1199, avg. train loss: 0.15936\n",
      "Step #1299, avg. train loss: 0.15088\n",
      "Step #1399, avg. train loss: 0.13383\n",
      "Step #1499, avg. train loss: 0.16450\n",
      "Step #1599, avg. train loss: 0.13923\n",
      "Step #1699, avg. train loss: 0.14694\n",
      "Step #1800, epoch #1, avg. train loss: 0.12194\n",
      "Step #1900, epoch #1, avg. train loss: 0.09737\n",
      "Step #2000, epoch #1, avg. train loss: 0.11367\n",
      "Step #2100, epoch #1, avg. train loss: 0.11900\n",
      "Step #2200, epoch #1, avg. train loss: 0.12048\n",
      "Step #2300, epoch #1, avg. train loss: 0.10333\n",
      "Step #2400, epoch #1, avg. train loss: 0.10295\n",
      "Step #2500, epoch #1, avg. train loss: 0.11920\n",
      "Step #2600, epoch #1, avg. train loss: 0.10857\n",
      "Step #2700, epoch #1, avg. train loss: 0.10065\n",
      "Step #2800, epoch #1, avg. train loss: 0.10823\n",
      "Step #2900, epoch #1, avg. train loss: 0.10323\n",
      "Step #3000, epoch #1, avg. train loss: 0.10692\n",
      "Step #3100, epoch #1, avg. train loss: 0.11168\n",
      "Step #3200, epoch #1, avg. train loss: 0.10160\n",
      "Step #3300, epoch #1, avg. train loss: 0.11945\n",
      "Step #3400, epoch #1, avg. train loss: 0.09656\n",
      "Step #3500, epoch #2, avg. train loss: 0.08695\n",
      "Step #3600, epoch #2, avg. train loss: 0.07957\n",
      "Step #3700, epoch #2, avg. train loss: 0.08308\n",
      "Step #3800, epoch #2, avg. train loss: 0.07566\n",
      "Step #3900, epoch #2, avg. train loss: 0.08046\n",
      "Step #4000, epoch #2, avg. train loss: 0.08104\n",
      "Step #4100, epoch #2, avg. train loss: 0.08058\n",
      "Step #4200, epoch #2, avg. train loss: 0.08044\n",
      "Step #4300, epoch #2, avg. train loss: 0.06608\n",
      "Step #4400, epoch #2, avg. train loss: 0.06437\n",
      "Step #4500, epoch #2, avg. train loss: 0.07829\n",
      "Step #4600, epoch #2, avg. train loss: 0.08326\n",
      "Step #4700, epoch #2, avg. train loss: 0.07003\n",
      "Step #4800, epoch #2, avg. train loss: 0.06185\n",
      "Step #4900, epoch #2, avg. train loss: 0.08231\n",
      "Step #5000, epoch #2, avg. train loss: 0.07669\n",
      "Test accuracy: 0.972100\n"
     ]
    }
   ],
   "source": [
    "# Single hidden layer with 100 nodes.\n",
    "classifier = learn.TensorFlowDNNClassifier(hidden_units=[100], n_classes=10, steps=5000)\n",
    "classifier.fit(mnist.train.images, transform(mnist.train.labels))\n",
    "score = metrics.accuracy_score(transform(mnist.test.labels), classifier.predict(mnist.test.images))\n",
    "print('Test accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.91334\n",
      "Step #199, avg. train loss: 0.40775\n",
      "Step #299, avg. train loss: 0.31625\n",
      "Step #399, avg. train loss: 0.26715\n",
      "Step #499, avg. train loss: 0.23502\n",
      "Step #599, avg. train loss: 0.21162\n",
      "Step #699, avg. train loss: 0.19028\n",
      "Step #799, avg. train loss: 0.18388\n",
      "Step #899, avg. train loss: 0.17726\n",
      "Step #999, avg. train loss: 0.17916\n",
      "Step #1099, avg. train loss: 0.14421\n",
      "Step #1199, avg. train loss: 0.13031\n",
      "Step #1299, avg. train loss: 0.13387\n",
      "Step #1399, avg. train loss: 0.12263\n",
      "Step #1499, avg. train loss: 0.14901\n",
      "Step #1599, avg. train loss: 0.12223\n",
      "Step #1699, avg. train loss: 0.13571\n",
      "Step #1800, epoch #1, avg. train loss: 0.09939\n",
      "Step #1900, epoch #1, avg. train loss: 0.08424\n",
      "Step #2000, epoch #1, avg. train loss: 0.08604\n",
      "Step #2100, epoch #1, avg. train loss: 0.09431\n",
      "Step #2200, epoch #1, avg. train loss: 0.09627\n",
      "Step #2300, epoch #1, avg. train loss: 0.08226\n",
      "Step #2400, epoch #1, avg. train loss: 0.08938\n",
      "Step #2500, epoch #1, avg. train loss: 0.10100\n",
      "Step #2600, epoch #1, avg. train loss: 0.09655\n",
      "Step #2700, epoch #1, avg. train loss: 0.08548\n",
      "Step #2800, epoch #1, avg. train loss: 0.09744\n",
      "Step #2900, epoch #1, avg. train loss: 0.08665\n",
      "Step #3000, epoch #1, avg. train loss: 0.09306\n",
      "Step #3100, epoch #1, avg. train loss: 0.09701\n",
      "Step #3200, epoch #1, avg. train loss: 0.08852\n",
      "Step #3300, epoch #1, avg. train loss: 0.09782\n",
      "Step #3400, epoch #1, avg. train loss: 0.08572\n",
      "Step #3500, epoch #2, avg. train loss: 0.06363\n",
      "Step #3600, epoch #2, avg. train loss: 0.05608\n",
      "Step #3700, epoch #2, avg. train loss: 0.06196\n",
      "Step #3800, epoch #2, avg. train loss: 0.06021\n",
      "Step #3900, epoch #2, avg. train loss: 0.05340\n",
      "Step #4000, epoch #2, avg. train loss: 0.05672\n",
      "Step #4100, epoch #2, avg. train loss: 0.05690\n",
      "Step #4200, epoch #2, avg. train loss: 0.06193\n",
      "Step #4300, epoch #2, avg. train loss: 0.04983\n",
      "Step #4400, epoch #2, avg. train loss: 0.05348\n",
      "Step #4500, epoch #2, avg. train loss: 0.06119\n",
      "Step #4600, epoch #2, avg. train loss: 0.07025\n",
      "Step #4700, epoch #2, avg. train loss: 0.04498\n",
      "Step #4800, epoch #2, avg. train loss: 0.04882\n",
      "Step #4900, epoch #2, avg. train loss: 0.05810\n",
      "Step #5000, epoch #2, avg. train loss: 0.05837\n",
      "Test accuracy: 0.978500\n"
     ]
    }
   ],
   "source": [
    "# 2 hidden layers with 100 nodes in each layer.\n",
    "classifier = learn.TensorFlowDNNClassifier(hidden_units=[200, 200], n_classes=10, steps=5000)\n",
    "classifier.fit(mnist.train.images, transform(mnist.train.labels))\n",
    "score = metrics.accuracy_score(transform(mnist.test.labels), classifier.predict(mnist.test.images))\n",
    "print('Test accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用skflow实现CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 1.68626\n",
      "Step #199, avg. train loss: 0.56969\n",
      "Step #299, avg. train loss: 0.37530\n",
      "Step #399, avg. train loss: 0.30172\n",
      "Step #499, avg. train loss: 0.25934\n",
      "Step #599, avg. train loss: 0.21123\n",
      "Step #699, avg. train loss: 0.18810\n",
      "Step #799, avg. train loss: 0.17963\n",
      "Step #900, epoch #1, avg. train loss: 0.16437\n",
      "Step #1000, epoch #1, avg. train loss: 0.13854\n",
      "Step #1100, epoch #1, avg. train loss: 0.13728\n",
      "Step #1200, epoch #1, avg. train loss: 0.13113\n",
      "Step #1300, epoch #1, avg. train loss: 0.12916\n",
      "Step #1400, epoch #1, avg. train loss: 0.12217\n",
      "Step #1500, epoch #1, avg. train loss: 0.11599\n",
      "Step #1600, epoch #1, avg. train loss: 0.11539\n",
      "Step #1700, epoch #1, avg. train loss: 0.11104\n",
      "Step #1800, epoch #2, avg. train loss: 0.10460\n",
      "Step #1900, epoch #2, avg. train loss: 0.10322\n",
      "Step #2000, epoch #2, avg. train loss: 0.10297\n",
      "Step #2100, epoch #2, avg. train loss: 0.09664\n",
      "Step #2200, epoch #2, avg. train loss: 0.08053\n",
      "Step #2300, epoch #2, avg. train loss: 0.08493\n",
      "Step #2400, epoch #2, avg. train loss: 0.07362\n",
      "Step #2500, epoch #2, avg. train loss: 0.08521\n",
      "Step #2600, epoch #3, avg. train loss: 0.08065\n",
      "Step #2700, epoch #3, avg. train loss: 0.08641\n",
      "Step #2800, epoch #3, avg. train loss: 0.07925\n",
      "Step #2900, epoch #3, avg. train loss: 0.07047\n",
      "Step #3000, epoch #3, avg. train loss: 0.07435\n",
      "Step #3100, epoch #3, avg. train loss: 0.06960\n",
      "Step #3200, epoch #3, avg. train loss: 0.08049\n",
      "Step #3300, epoch #3, avg. train loss: 0.06356\n",
      "Step #3400, epoch #3, avg. train loss: 0.07041\n",
      "Step #3500, epoch #4, avg. train loss: 0.06503\n",
      "Step #3600, epoch #4, avg. train loss: 0.06466\n",
      "Step #3700, epoch #4, avg. train loss: 0.06137\n",
      "Step #3800, epoch #4, avg. train loss: 0.06156\n",
      "Step #3900, epoch #4, avg. train loss: 0.06336\n",
      "Step #4000, epoch #4, avg. train loss: 0.06783\n",
      "Step #4100, epoch #4, avg. train loss: 0.06996\n",
      "Step #4200, epoch #4, avg. train loss: 0.05245\n",
      "Step #4300, epoch #5, avg. train loss: 0.05117\n",
      "Step #4400, epoch #5, avg. train loss: 0.05576\n",
      "Step #4500, epoch #5, avg. train loss: 0.05555\n",
      "Step #4600, epoch #5, avg. train loss: 0.05311\n",
      "Step #4700, epoch #5, avg. train loss: 0.05438\n",
      "Step #4800, epoch #5, avg. train loss: 0.05494\n",
      "Step #4900, epoch #5, avg. train loss: 0.05337\n",
      "Step #5000, epoch #5, avg. train loss: 0.05903\n",
      "Test accuracy: 0.988100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def max_pool_2x2(tensor_in):\n",
    "    return tf.nn.max_pool(tensor_in, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def conv_model(X, y):\n",
    "    # reshape X to 4d tensor with 2nd and 3rd dimensions being image width and height\n",
    "    # final dimension being the number of color channels\n",
    "    X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    # first conv layer will compute 32 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer1'):\n",
    "        h_conv1 = learn.ops.conv2d(X, n_filters=32, filter_shape=[5, 5], \n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    # second conv layer will compute 64 features for each 5x5 patch\n",
    "    with tf.variable_scope('conv_layer2'):\n",
    "        h_conv2 = learn.ops.conv2d(h_pool1, n_filters=64, filter_shape=[5, 5], \n",
    "                                    bias=True, activation=tf.nn.relu)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # reshape tensor into a batch of vectors\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    # densely connected layer with 512 neurons\n",
    "    h_fc1 = learn.ops.dnn(h_pool2_flat, [512], activation=tf.nn.relu, dropout=0.5)\n",
    "    return learn.models.logistic_regression(h_fc1, y)\n",
    "\n",
    "# Training and predicting\n",
    "classifier = learn.TensorFlowEstimator(\n",
    "    model_fn=conv_model, n_classes=10, batch_size=64, steps=5000, learning_rate=0.01)\n",
    "classifier.fit(mnist.train.images, transform(mnist.train.labels))\n",
    "score = metrics.accuracy_score(transform(mnist.test.labels), classifier.predict(mnist.test.images))\n",
    "print('Test accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
